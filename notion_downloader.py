#!/usr/bin/env python3
"""
Notion API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼
Obsidianãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«Notionãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜ã™ã‚‹ãƒ„ãƒ¼ãƒ«
"""

import os
import json
import requests
from datetime import datetime
from pathlib import Path
import argparse
from typing import Dict, List, Optional

class NotionDownloader:
    def __init__(self, token: str, base_path: str = "."):
        """
        NotionDownloaderã®åˆæœŸåŒ–
        
        Args:
            token (str): Notion API ãƒˆãƒ¼ã‚¯ãƒ³
            base_path (str): ä¿å­˜å…ˆã®ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
        """
        self.token = token
        self.base_path = Path(base_path)
        self.headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
            "Notion-Version": "2022-06-28"
        }
        
    def get_page_content(self, page_id: str) -> Dict:
        """
        ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—
        
        Args:
            page_id (str): Notionãƒšãƒ¼ã‚¸ID
            
        Returns:
            Dict: ãƒšãƒ¼ã‚¸ã®å†…å®¹
        """
        url = f"https://api.notion.com/v1/pages/{page_id}"
        response = requests.get(url, headers=self.headers)
        response.raise_for_status()
        return response.json()
    
    def get_block_children(self, block_id: str) -> List[Dict]:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã®å­è¦ç´ ã‚’å–å¾—
        
        Args:
            block_id (str): ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            List[Dict]: å­ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ
        """
        url = f"https://api.notion.com/v1/blocks/{block_id}/children"
        response = requests.get(url, headers=self.headers)
        response.raise_for_status()
        return response.json()["results"]
    
    def search_pages(self, query: str = "") -> List[Dict]:
        """
        ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢
        
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
            
        Returns:
            List[Dict]: æ¤œç´¢çµæœã®ãƒšãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
        """
        url = "https://api.notion.com/v1/search"
        data = {
            "query": query,
            "filter": {
                "property": "object",
                "value": "page"
            }
        }
        response = requests.post(url, headers=self.headers, json=data)
        response.raise_for_status()
        return response.json()["results"]
    
    def block_to_markdown(self, block: Dict) -> str:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚’Markdownã«å¤‰æ›
        
        Args:
            block (Dict): Notionãƒ–ãƒ­ãƒƒã‚¯
            
        Returns:
            str: Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆ
        """
        block_type = block["type"]
        content = block[block_type]
        
        if block_type == "paragraph":
            text = self._extract_text(content.get("rich_text", []))
            return f"{text}\n\n"
        
        elif block_type == "heading_1":
            text = self._extract_text(content.get("rich_text", []))
            return f"# {text}\n\n"
        
        elif block_type == "heading_2":
            text = self._extract_text(content.get("rich_text", []))
            return f"## {text}\n\n"
        
        elif block_type == "heading_3":
            text = self._extract_text(content.get("rich_text", []))
            return f"### {text}\n\n"
        
        elif block_type == "bulleted_list_item":
            text = self._extract_text(content.get("rich_text", []))
            return f"- {text}\n"
        
        elif block_type == "numbered_list_item":
            text = self._extract_text(content.get("rich_text", []))
            return f"1. {text}\n"
        
        elif block_type == "to_do":
            text = self._extract_text(content.get("rich_text", []))
            checked = content.get("checked", False)
            checkbox = "[x]" if checked else "[ ]"
            return f"{checkbox} {text}\n"
        
        elif block_type == "code":
            text = self._extract_text(content.get("rich_text", []))
            language = content.get("language", "")
            return f"```{language}\n{text}\n```\n\n"
        
        elif block_type == "quote":
            text = self._extract_text(content.get("rich_text", []))
            return f"> {text}\n\n"
        
        elif block_type == "callout":
            text = self._extract_text(content.get("rich_text", []))
            icon = content.get("icon", {}).get("emoji", "ğŸ’¡")
            return f"{icon} {text}\n\n"
        
        elif block_type == "divider":
            return "---\n\n"
        
        elif block_type == "image":
            image_url = content.get("external", {}).get("url") or content.get("file", {}).get("url")
            caption = self._extract_text(content.get("caption", []))
            caption_text = f" {caption}" if caption else ""
            return f"![{caption}]({image_url}){caption_text}\n\n"
        
        elif block_type == "table_of_contents":
            return "[[ç›®æ¬¡]]\n\n"
        
        else:
            # æœªå¯¾å¿œã®ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—
            return f"<!-- æœªå¯¾å¿œãƒ–ãƒ­ãƒƒã‚¯: {block_type} -->\n\n"
    
    def _extract_text(self, rich_text: List[Dict]) -> str:
        """
       ãƒªãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        
        Args:
            rich_text (List[Dict]): ãƒªãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
            
        Returns:
            str: ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        text_parts = []
        for text_block in rich_text:
            if text_block.get("type") == "text":
                text_content = text_block["text"]["content"]
                annotations = text_block.get("annotations", {})
                
                # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨
                if annotations.get("bold"):
                    text_content = f"**{text_content}**"
                if annotations.get("italic"):
                    text_content = f"*{text_content}*"
                if annotations.get("strikethrough"):
                    text_content = f"~~{text_content}~~"
                if annotations.get("code"):
                    text_content = f"`{text_content}`"
                
                # ãƒªãƒ³ã‚¯ã‚’å‡¦ç†
                if text_block["text"].get("link"):
                    link_url = text_block["text"]["link"]["url"]
                    text_content = f"[{text_content}]({link_url})"
                
                text_parts.append(text_content)
        
        return "".join(text_parts)
    
    def get_page_title(self, page: Dict) -> str:
        """
        ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
        
        Args:
            page (Dict): ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            str: ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«
        """
        properties = page.get("properties", {})
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ¢ã™
        for prop_name, prop_value in properties.items():
            if prop_value.get("type") == "title":
                title_blocks = prop_value["title"]
                if title_blocks:
                    return self._extract_text(title_blocks)
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒšãƒ¼ã‚¸IDã‚’ä½¿ç”¨
        return f"Untitled-{page['id'][:8]}"
    
    def download_page(self, page_id: str, output_dir: Optional[str] = None) -> str:
        """
        ãƒšãƒ¼ã‚¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        
        Args:
            page_id (str): Notionãƒšãƒ¼ã‚¸ID
            output_dir (Optional[str]): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: base_pathï¼‰
            
        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        print(f"ãƒšãƒ¼ã‚¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {page_id}")
        
        # ãƒšãƒ¼ã‚¸æƒ…å ±ã‚’å–å¾—
        page = self.get_page_content(page_id)
        title = self.get_page_title(page)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆå®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›ï¼‰
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_title = safe_title.replace(' ', '_')
        filename = f"{safe_title}.md"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±ºå®š
        if output_dir:
            output_path = Path(output_dir)
        else:
            output_path = self.base_path
        
        output_path.mkdir(parents=True, exist_ok=True)
        file_path = output_path / filename
        
        # ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—
        blocks = self.get_block_children(page_id)
        
        # Markdownã«å¤‰æ›
        markdown_content = []
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        markdown_content.append(f"# {title}\n")
        markdown_content.append(f"**ä½œæˆæ—¥**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        markdown_content.append(f"**Notionãƒšãƒ¼ã‚¸ID**: {page_id}\n")
        markdown_content.append(f"**URL**: https://notion.so/{page_id.replace('-', '')}\n\n")
        markdown_content.append("---\n\n")
        
        # ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡¦ç†
        for block in blocks:
            markdown_content.append(self.block_to_markdown(block))
            
            # å­ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯å†å¸°çš„ã«å‡¦ç†
            if block.get("has_children", False):
                child_blocks = self.get_block_children(block["id"])
                for child_block in child_blocks:
                    markdown_content.append(self.block_to_markdown(child_block))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(''.join(markdown_content))
        
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {file_path}")
        return str(file_path)
    
    def download_database(self, database_id: str, output_dir: Optional[str] = None) -> List[str]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å…¨ãƒšãƒ¼ã‚¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        Args:
            database_id (str): Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ID
            output_dir (Optional[str]): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            List[str]: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
        """
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {database_id}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
        url = f"https://api.notion.com/v1/databases/{database_id}/query"
        response = requests.post(url, headers=self.headers, json={})
        response.raise_for_status()
        
        pages = response.json()["results"]
        saved_files = []
        
        for page in pages:
            page_id = page["id"]
            try:
                file_path = self.download_page(page_id, output_dir)
                saved_files.append(file_path)
            except Exception as e:
                print(f"ãƒšãƒ¼ã‚¸ {page_id} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        
        return saved_files

def main():
    parser = argparse.ArgumentParser(description="Notion API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼")
    parser.add_argument("--token", required=True, help="Notion API ãƒˆãƒ¼ã‚¯ãƒ³")
    parser.add_argument("--page-id", help="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒšãƒ¼ã‚¸ID")
    parser.add_argument("--database-id", help="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ID")
    parser.add_argument("--search", help="æ¤œç´¢ã‚¯ã‚¨ãƒª")
    parser.add_argument("--output-dir", default=".", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--list-pages", action="store_true", help="åˆ©ç”¨å¯èƒ½ãªãƒšãƒ¼ã‚¸ã‚’ä¸€è¦§è¡¨ç¤º")
    
    args = parser.parse_args()
    
    downloader = NotionDownloader(args.token, args.output_dir)
    
    if args.list_pages:
        print("åˆ©ç”¨å¯èƒ½ãªãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ä¸­...")
        pages = downloader.search_pages(args.search or "")
        print(f"\nè¦‹ã¤ã‹ã£ãŸãƒšãƒ¼ã‚¸æ•°: {len(pages)}")
        for i, page in enumerate(pages, 1):
            title = downloader.get_page_title(page)
            page_id = page["id"]
            print(f"{i}. {title} (ID: {page_id})")
    
    elif args.page_id:
        try:
            file_path = downloader.download_page(args.page_id, args.output_dir)
            print(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {file_path}")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif args.database_id:
        try:
            file_paths = downloader.download_database(args.database_id, args.output_dir)
            print(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(file_paths)} ãƒ•ã‚¡ã‚¤ãƒ«")
            for file_path in file_paths:
                print(f"  - {file_path}")
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 